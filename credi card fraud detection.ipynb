{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#null valuew\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class distribution\n",
    "sns.countplot('Class',data=df)\n",
    "plt.title('class distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--Distribution of Transaction Time and Transaction Money\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(18,4))\n",
    "sns.distplot(df['Time'].values,ax=axes[0])\n",
    "axes[0].set_title('Distribution of Transaction Time')\n",
    "axes[0].set_xlim([min(df['Time'].values), max(df['Time'].values)])\n",
    "\n",
    "sns.distplot(df['Amount'].values,ax=axes[1],color='r')\n",
    "axes[1].set_title('Distribution of Transaction Amount')\n",
    "axes[1].set_xlim([min(df['Amount'].values), max(df['Amount'].values)])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler,RobustScaler\n",
    "rob_scaler=RobustScaler()\n",
    "df['scaled_amount'] = rob_scaler.fit_transform(df['Amount'].values.reshape(-1,1))\n",
    "df['scaled_time'] = rob_scaler.fit_transform(df['Time'].values.reshape(-1,1))\n",
    "\n",
    "df.drop(['Time','Amount'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_amount = df['scaled_amount']\n",
    "scaled_time = df['scaled_time']\n",
    "\n",
    "df.drop(['scaled_amount', 'scaled_time'], axis=1, inplace=True)\n",
    "df.insert(0, 'scaled_amount', scaled_amount)\n",
    "df.insert(1, 'scaled_time', scaled_time)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation with Class\n",
    "index=df.corrwith(df['Class']).sort_values(ascending=False).index\n",
    "plt.figure(figsize=(25,30))\n",
    "sns.barplot(x=df.corrwith(df['Class']).sort_values(ascending=False),y=index,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplot of highest neative correlaton\n",
    "f, axes = plt.subplots(ncols=2,nrows=2 ,figsize=(20,20))\n",
    "\n",
    "sns.boxplot(x=\"Class\", y=\"V17\", data=df, ax=axes[0,0])\n",
    "axes[0,0].set_title('V17 vs Class Negative Correlation')\n",
    "\n",
    "sns.boxplot(x=\"Class\", y=\"V14\", data=df, ax=axes[0,1])\n",
    "axes[0,1].set_title('V14 vs Class Negative Correlation')\n",
    "\n",
    "\n",
    "sns.boxplot(x=\"Class\", y=\"V12\", data=df, ax=axes[1,0])\n",
    "axes[1,0].set_title('V12 vs Class Negative Correlation')\n",
    "\n",
    "\n",
    "sns.boxplot(x=\"Class\", y=\"V10\", data=df, ax=axes[1,1])\n",
    "axes[1,1].set_title('V10 vs Class Negative Correlation')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -----> V14 Removing Outliers (Highest Negative Correlated with Labels)\n",
    "v14_fraud = df['V14'].loc[df['Class'] == 1].values\n",
    "q25, q75 = np.percentile(v14_fraud, 25), np.percentile(v14_fraud, 75)\n",
    "v14_iqr = q75 - q25\n",
    "\n",
    "v14_cut_off = v14_iqr * 1.5\n",
    "v14_lower, v14_upper = q25 - v14_cut_off, q75 + v14_cut_off\n",
    "outliers = [x for x in v14_fraud if x < v14_lower or x > v14_upper]\n",
    "df = df.drop(df[(df['V14'] > v14_upper) | (df['V14'] < v14_lower)].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -----> V12 Removing Outliers (Highest Negative Correlated with Labels)\n",
    "v12_fraud = df['V12'].loc[df['Class'] == 1].values\n",
    "q25, q75 = np.percentile(v12_fraud, 25), np.percentile(v12_fraud, 75)\n",
    "v12_iqr = q75 - q25\n",
    "\n",
    "v12_cut_off = v12_iqr * 1.5\n",
    "v12_lower, v12_upper = q25 - v12_cut_off, q75 + v12_cut_off\n",
    "outliers = [x for x in v12_fraud if x < v12_lower or x > v12_upper]\n",
    "df = df.drop(df[(df['V12'] > v12_upper) | (df['V12'] < v12_lower)].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -----> V10 Removing Outliers (Highest Negative Correlated with Labels)\n",
    "v10_fraud = df['V10'].loc[df['Class'] == 1].values\n",
    "q25, q75 = np.percentile(v10_fraud, 25), np.percentile(v10_fraud, 75)\n",
    "v10_iqr = q75 - q25\n",
    "\n",
    "v10_cut_off = v10_iqr * 1.5\n",
    "v10_lower, v10_upper = q25 - v10_cut_off, q75 + v10_cut_off\n",
    "outliers = [x for x in v10_fraud if x < v10_lower or x > v10_upper]\n",
    "df = df.drop(df[(df['V10'] > v10_upper) | (df['V10'] < v10_lower)].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplot after removal of outliers\n",
    "f, axes = plt.subplots(ncols=1,nrows=3 ,figsize=(20,20))\n",
    "\n",
    "sns.boxplot(x=\"Class\", y=\"V14\", data=df, ax=axes[0])\n",
    "axes[0].set_title('V14 vs Class Negative Correlation')\n",
    "\n",
    "\n",
    "sns.boxplot(x=\"Class\", y=\"V12\", data=df, ax=axes[1])\n",
    "axes[1].set_title('V12 vs Class Negative Correlation')\n",
    "\n",
    "\n",
    "sns.boxplot(x=\"Class\", y=\"V10\", data=df, ax=axes[2])\n",
    "axes[2].set_title('V10 vs Class Negative Correlation')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "import xgboost\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "accuracy={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit,StratifiedKFold\n",
    "\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "sss = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]\n",
    "    original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "\n",
    "X_train = original_Xtrain.values\n",
    "X_test = original_Xtest.values\n",
    "y_train = original_ytrain.values\n",
    "y_test = original_ytest.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=['train','test'],y=[(y_train==1).sum()/y_train.shape[0],(y_test==1).sum()/y_test.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LogisticRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred=lr.predict(X_test)\n",
    "acc=accuracy_score(y_test,y_pred)\n",
    "con=confusion_matrix(y_test,y_pred)\n",
    "accuracy['logisticRegression']=[acc,con]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd=SGDClassifier()\n",
    "sgd.fit(X_train,y_train)\n",
    "y_pred=sgd.predict(X_test)\n",
    "acc=accuracy_score(y_test,y_pred)\n",
    "con=confusion_matrix(y_test,y_pred)\n",
    "accuracy['sgdClassifier']=[acc,con]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb=xgboost.XGBClassifier(max_depth=3,n_estimators=100)\n",
    "xgb.fit(X_train,y_train)\n",
    "y_pred=xgb.predict(X_test)\n",
    "acc=accuracy_score(y_test,y_pred)\n",
    "con=confusion_matrix(y_test,y_pred)\n",
    "accuracy['xgbclassifier']=[acc,con]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforestclassifier=RandomForestClassifier()\n",
    "randomforestclassifier.fit(X_train,y_train)\n",
    "y_pred=randomforestclassifier.predict(X_test)\n",
    "acc=accuracy_score(y_test,y_pred)\n",
    "con=confusion_matrix(y_test,y_pred)\n",
    "accuracy['randomforest']=[acc,con]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost=AdaBoostClassifier()\n",
    "adaboost.fit(X_train,y_train)\n",
    "y_pred=adaboost.predict(X_test)\n",
    "acc=accuracy_score(y_test,y_pred)\n",
    "con=confusion_matrix(y_test,y_pred)\n",
    "accuracy['adaboost']=[acc,con]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradientboosting=GradientBoostingClassifier()\n",
    "gradientboosting.fit(X_train,y_train)\n",
    "y_pred=gradientboosting.predict(X_test)\n",
    "acc=accuracy_score(y_test,y_pred)\n",
    "con=confusion_matrix(y_test,y_pred)\n",
    "accuracy['gradientboosting']=[acc,con]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy of all model\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc=[accuracy['logisticRegression'][0],accuracy['sgdClassifier'][0],accuracy['xgbclassifier'][0],accuracy['randomforest'][0],accuracy['adaboost'][0],accuracy['gradientboosting'][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=['logisticRegression','sgdClassifier','xgbclassifier','randomforest','adaboost','gradientboosting'],y=acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "\n",
    "n_inputs = X_train.shape[1]\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(n_inputs, input_shape=(n_inputs, ), activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, validation_split=0.2, batch_size=25, epochs=20, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_test,batch_size=200)\n",
    "y_p=y_pred>0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(confusion_matrix(y_test,y_p), xticklabels=['No Fraud', 'Fraud'],yticklabels=['No Fraud', 'Fraud'],annot=True,cbar=True, cmap=plt.cm.Oranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,y_p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
